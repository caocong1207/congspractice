{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "469ebc3b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-07-08T05:38:37.396118Z",
     "iopub.status.busy": "2023-07-08T05:38:37.395611Z",
     "iopub.status.idle": "2023-07-08T05:38:37.407379Z",
     "shell.execute_reply": "2023-07-08T05:38:37.406530Z"
    },
    "papermill": {
     "duration": 0.018726,
     "end_time": "2023-07-08T05:38:37.409453",
     "exception": false,
     "start_time": "2023-07-08T05:38:37.390727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b60dd0ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-08T05:38:37.416155Z",
     "iopub.status.busy": "2023-07-08T05:38:37.415530Z",
     "iopub.status.idle": "2023-07-08T05:38:40.532408Z",
     "shell.execute_reply": "2023-07-08T05:38:40.531285Z"
    },
    "papermill": {
     "duration": 3.123093,
     "end_time": "2023-07-08T05:38:40.535171",
     "exception": false,
     "start_time": "2023-07-08T05:38:37.412078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = '../input/store-sales-time-series-forecasting/'\n",
    "\n",
    "sub = pd.read_csv(path + 'sample_submission.csv')\n",
    "\n",
    "holiday_df = pd.read_csv(path + 'holidays_events.csv')\n",
    "oil_df = pd.read_csv(path + 'oil.csv')\n",
    "test_df = pd.read_csv(path + 'test.csv')\n",
    "tran_df = pd.read_csv(path + 'transactions.csv')\n",
    "train_df = pd.read_csv(path + 'train.csv')\n",
    "store_df = pd.read_csv(path + 'stores.csv')\n",
    "#sales_df = pd.read_csv(path + 'sales.csv')\n",
    "#cities_df = pd.read_csv(path + 'cities.csv')\n",
    "#product_lines_df = pd.read_csv('product_lines.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a132670a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-08T05:38:40.541755Z",
     "iopub.status.busy": "2023-07-08T05:38:40.541394Z",
     "iopub.status.idle": "2023-07-08T05:38:41.823048Z",
     "shell.execute_reply": "2023-07-08T05:38:41.821977Z"
    },
    "papermill": {
     "duration": 1.288405,
     "end_time": "2023-07-08T05:38:41.826246",
     "exception": false,
     "start_time": "2023-07-08T05:38:40.537841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 stores by total sales:\n",
      "store_nbr\n",
      "44    6.208755e+07\n",
      "45    5.449801e+07\n",
      "47    5.094831e+07\n",
      "3     5.048191e+07\n",
      "49    4.342010e+07\n",
      "Name: sales, dtype: float64\n",
      "\n",
      "Top 5 cities by total sales:\n",
      "city\n",
      "Quito            5.567418e+08\n",
      "Guayaquil        1.229673e+08\n",
      "Cuenca           4.916860e+07\n",
      "Ambato           4.030440e+07\n",
      "Santo Domingo    3.583432e+07\n",
      "Name: sales, dtype: float64\n",
      "\n",
      "Top 10 product lines by total sales:\n",
      "family\n",
      "GROCERY I        3.434627e+08\n",
      "BEVERAGES        2.169545e+08\n",
      "PRODUCE          1.227047e+08\n",
      "CLEANING         9.752129e+07\n",
      "DAIRY            6.448771e+07\n",
      "BREAD/BAKERY     4.213395e+07\n",
      "POULTRY          3.187600e+07\n",
      "MEATS            3.108647e+07\n",
      "PERSONAL CARE    2.459205e+07\n",
      "DELI             2.411032e+07\n",
      "Name: sales, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV files into pandas DataFrames\n",
    "\n",
    "# Merge the necessary information from different DataFrames for total sales\n",
    "merged_data = pd.merge(train_df, store_df, on='store_nbr')\n",
    "\n",
    "# Calculate the total sales for each store\n",
    "store_sales = train_df.groupby('store_nbr')['sales'].sum().sort_values(ascending=False)\n",
    "#store_sales = data.groupby('store_nbr')['sales'].sum()\n",
    "\n",
    "\n",
    "# Get the top 5 stores with the highest total sales\n",
    "top_5_stores = store_sales.head(5)\n",
    "\n",
    "# Calculate the total sales for each city\n",
    "city_sales = merged_data.groupby('city')['sales'].sum().sort_values(ascending=False)\n",
    "\n",
    "\n",
    "# Get the top 5 cities with the highest total sales\n",
    "top_5_cities = city_sales.head(5)\n",
    "\n",
    "# Calculate the total sales for each product family\n",
    "family_sales = train_df.groupby('family')['sales'].sum()\n",
    "\n",
    "# Sort the product families based on sales in descending order\n",
    "sorted_family_sales = family_sales.sort_values(ascending=False)\n",
    "\n",
    "# Get the top 10 families with the most sales\n",
    "top_10_families = sorted_family_sales.head(10)\n",
    "\n",
    "\n",
    "\n",
    "# Print the results\n",
    "print(\"Top 5 stores by total sales:\")\n",
    "print(top_5_stores)\n",
    "print(\"\\nTop 5 cities by total sales:\")\n",
    "print(top_5_cities)\n",
    "print(\"\\nTop 10 product lines by total sales:\")\n",
    "print(top_10_families)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86a2c324",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-08T05:38:41.833106Z",
     "iopub.status.busy": "2023-07-08T05:38:41.832456Z",
     "iopub.status.idle": "2023-07-08T05:38:42.636804Z",
     "shell.execute_reply": "2023-07-08T05:38:42.635542Z"
    },
    "papermill": {
     "duration": 0.810232,
     "end_time": "2023-07-08T05:38:42.639178",
     "exception": false,
     "start_time": "2023-07-08T05:38:41.828946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store_nbr\n",
      "53    0.509542\n",
      "43    0.321299\n",
      "42    0.230761\n",
      "26    0.226196\n",
      "41    0.225012\n",
      "Name: sales, dtype: float64\n",
      "store_nbr\n",
      "13   -0.049202\n",
      "16   -0.046178\n",
      "19   -0.026257\n",
      "33   -0.009664\n",
      "10    0.009099\n",
      "Name: sales, dtype: float64\n",
      "city\n",
      "Manta         0.509542\n",
      "Esmeraldas    0.321299\n",
      "Puyo          0.216018\n",
      "Machala       0.177596\n",
      "Daule         0.156919\n",
      "Name: growth_rate, dtype: float64\n",
      "city\n",
      "Guaranda    -0.026257\n",
      "Latacunga   -0.012098\n",
      "Quevedo     -0.009664\n",
      "Playas       0.009744\n",
      "Libertad     0.022058\n",
      "Name: growth_rate, dtype: float64\n",
      "store_nbr\n",
      "53    0.509542\n",
      "43    0.321299\n",
      "42    0.230761\n",
      "26    0.226196\n",
      "41    0.225012\n",
      "22    0.216018\n",
      "29    0.185927\n",
      "32    0.185286\n",
      "21    0.183100\n",
      "17    0.170502\n",
      "Name: growth_rate, dtype: float64\n",
      "store_nbr\n",
      "13   -0.049202\n",
      "16   -0.046178\n",
      "19   -0.026257\n",
      "33   -0.009664\n",
      "10    0.009099\n",
      "35    0.009744\n",
      "36    0.022058\n",
      "12    0.025006\n",
      "31    0.025782\n",
      "25    0.026104\n",
      "Name: growth_rate, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Convert the date column to datetime format\n",
    "train_df['date'] = pd.to_datetime(train_df['date'])\n",
    "\n",
    "# Extract the year and month from the date column\n",
    "train_df['year_month'] = train_df['date'].dt.to_period('M')\n",
    "\n",
    "# Filter the data for the first three months of 2016 and 2017\n",
    "data_2016 = train_df[train_df['year_month'].between('2016-01', '2016-03')]\n",
    "data_2017 = train_df[train_df['year_month'].between('2017-01', '2017-03')]\n",
    "\n",
    "# Calculate the total sales for each store in the first three months of 2016 and 2017\n",
    "sales_2016 = data_2016.groupby('store_nbr')['sales'].sum()\n",
    "sales_2017 = data_2017.groupby('store_nbr')['sales'].sum()\n",
    "\n",
    "# Calculate the growth rate for each store\n",
    "growth_rate = (sales_2017 - sales_2016) / sales_2016\n",
    "\n",
    "# Sort the stores based on growth rate in descending order\n",
    "most_growth_rate = growth_rate.sort_values(ascending=False)\n",
    "least_growth_rate = growth_rate.sort_values(ascending=True)\n",
    "\n",
    "# Get the top 5 stores with the highest growth rate\n",
    "top_5_stores = most_growth_rate.head(5)\n",
    "bot_5_stores = least_growth_rate.head(5)\n",
    "\n",
    "# Merge the sales data with the stores data based on store_nbr\n",
    "merged_data = pd.merge(sales_2016, sales_2017, left_index=True, right_index=True)\n",
    "merged_data = pd.merge(merged_data, store_df, left_index=True, right_on='store_nbr')\n",
    "\n",
    "# Calculate the growth rate for each city\n",
    "merged_data['growth_rate'] = (merged_data['sales_y'] - merged_data['sales_x']) / merged_data['sales_x']\n",
    "\n",
    "# Group the data by city and calculate the average growth rate\n",
    "city_growth_rate = merged_data.groupby('city')['growth_rate'].mean()\n",
    "\n",
    "# Sort the cities based on growth rate in descending order\n",
    "max_growth_rate = city_growth_rate.sort_values(ascending=False)\n",
    "min_growth_rate = city_growth_rate.sort_values(ascending=True)\n",
    "\n",
    "# Get the top 5 cities with the highest growth rate\n",
    "top_5_cities = max_growth_rate.head(5)\n",
    "bot_5_cities = min_growth_rate.head(5)\n",
    "\n",
    "# Merge the sales data for 2016 and 2017 based on product family\n",
    "merged_data_product = pd.merge(sales_2016, sales_2017, left_index=True, right_index=True)\n",
    "\n",
    "# Calculate the growth rate for each product family\n",
    "merged_data_product['growth_rate'] = (merged_data_product['sales_y'] - merged_data_product['sales_x']) / merged_data_product['sales_x']\n",
    "\n",
    "# Sort the product families based on growth rate in descending order\n",
    "max_growth_rate = merged_data_product['growth_rate'].sort_values(ascending=False)\n",
    "min_growth_rate = merged_data_product['growth_rate'].sort_values(ascending=True)\n",
    "\n",
    "# Get the top 10 product families with the highest growth rate\n",
    "top_10_families = max_growth_rate.head(10)\n",
    "bot_10_families = min_growth_rate.head(10)\n",
    "\n",
    "\n",
    "# Display the top 5 stores with the highest growth rate\n",
    "print(top_5_stores)\n",
    "print(bot_5_stores)\n",
    "print(top_5_cities)\n",
    "print(bot_5_cities)\n",
    "print(top_10_families)\n",
    "print(bot_10_families)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9bfe01f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-08T05:38:42.646379Z",
     "iopub.status.busy": "2023-07-08T05:38:42.645952Z",
     "iopub.status.idle": "2023-07-08T05:38:52.834296Z",
     "shell.execute_reply": "2023-07-08T05:38:52.833283Z"
    },
    "papermill": {
     "duration": 10.194405,
     "end_time": "2023-07-08T05:38:52.836522",
     "exception": false,
     "start_time": "2023-07-08T05:38:42.642117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between Oil Prices and Sales:  -0.07495842888642766\n"
     ]
    }
   ],
   "source": [
    "# Convert the date columns to datetime format\n",
    "train_df['date'] = pd.to_datetime(train_df['date'])\n",
    "oil_df['date'] = pd.to_datetime(oil_df['date'])\n",
    "\n",
    "# Extract the year and month from the date columns\n",
    "train_df['year_month'] = train_df['date'].dt.to_period('M')\n",
    "oil_df['year_month'] = oil_df['date'].dt.to_period('M')\n",
    "\n",
    "# Merge the oil prices with the sales data based on the year and month\n",
    "merged_data = pd.merge(train_df, oil_df, on='year_month')\n",
    "# Calculate the correlation between oil prices and sales\n",
    "correlation = merged_data['sales'].corr(merged_data['dcoilwtico'])\n",
    "\n",
    "# Display the correlation coefficient\n",
    "print(\"Correlation between Oil Prices and Sales: \", correlation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a87a981",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-08T05:38:52.843855Z",
     "iopub.status.busy": "2023-07-08T05:38:52.843268Z",
     "iopub.status.idle": "2023-07-08T05:39:06.753386Z",
     "shell.execute_reply": "2023-07-08T05:39:06.752289Z"
    },
    "papermill": {
     "duration": 13.916153,
     "end_time": "2023-07-08T05:39:06.755514",
     "exception": false,
     "start_time": "2023-07-08T05:38:52.839361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20/4219280582.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  family_correlations = merged_data.groupby('family')['sales', 'dcoilwtico'].corr().unstack()['sales']['dcoilwtico']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Affected Product Family:  family\n",
      "LINGERIE           0.083576\n",
      "HOME APPLIANCES    0.026211\n",
      "MEATS             -0.026203\n",
      "SEAFOOD           -0.043230\n",
      "GROCERY II        -0.058283\n",
      "Name: dcoilwtico, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the correlation between oil prices and sales for each product family\n",
    "family_correlations = merged_data.groupby('family')['sales', 'dcoilwtico'].corr().unstack()['sales']['dcoilwtico']\n",
    "\n",
    "# Sort the correlations in descending order\n",
    "sorted_correlations = family_correlations.sort_values(ascending=False)\n",
    "\n",
    "# Get the product family with the highest correlation\n",
    "most_affected_family = sorted_correlations.idxmax()\n",
    "top = sorted_correlations.head(5)\n",
    "# Display the most affected family\n",
    "print(\"Most Affected Product Family: \", top)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 40.215838,
   "end_time": "2023-07-08T05:39:07.781553",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-07-08T05:38:27.565715",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
